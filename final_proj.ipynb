{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install eli5 category_encoders # for colab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import eli5\n",
    "from   utils                   import *\n",
    "from   sklearn.compose         import *\n",
    "from   sklearn.experimental    import enable_iterative_imputer\n",
    "from   sklearn.impute          import *\n",
    "from   sklearn.linear_model    import *\n",
    "from   sklearn.ensemble        import *\n",
    "from   sklearn.tree            import *\n",
    "from   sklearn.svm             import LinearSVR\n",
    "from   sklearn.metrics         import *\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   sklearn.pipeline        import Pipeline\n",
    "from   sklearn.preprocessing   import *\n",
    "from   sklearn.base            import BaseEstimator, TransformerMixin\n",
    "from   sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from   sklearn.inspection      import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-language",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/luciaharley/London-Bike-ML/blob/main/final_proj.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-corrections",
   "metadata": {},
   "source": [
    "# Research question:  \n",
    "Can a linear or tree-based regression model be used to predict the number of bikes rented on a given day in London?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-spirit",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hidden-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('https://raw.githubusercontent.com/luciaharley/London-Bike-ML/main/london_merged.csv')\n",
    "X = bikes.drop(['cnt'], axis=1)\n",
    "y = np.ravel(bikes[['cnt']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-poster",
   "metadata": {},
   "source": [
    "# Fit initial model\n",
    "Fit a simple OLS linear regression with no feature engineering to serve as a baseline for target metrics. I will evaluate this model (and all models going forward) using R2, MAE, and RMSE. R2 gives a comparison to a baseline, \"y-bar\" regressor, MAE gives error in the same units as y, and RMSE is less sensitive to outliers. These are the most common metrics for regressors and together they give a broad interpretation of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "corporate-strength",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 681.05864513304, RMSE: 916.3569853519175, R2: 0.26591993698516136\n"
     ]
    }
   ],
   "source": [
    "X_init = X.drop(['timestamp'], axis=1)\n",
    "X_train_init, X_validation_init, y_train_init, y_validation_init = train_test_split(X_init, y)\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_init, y_train_init)\n",
    "y_pred = lm.predict(X_validation_init)\n",
    "mae = mean_absolute_error(y_validation_init, y_pred) #ground truth then predicted set\n",
    "rmse = np.sqrt(mean_squared_error(y_validation_init, y_pred))\n",
    "r2 = r2_score(y_validation_init, y_pred)\n",
    "print(f\"MAE: {mae}, RMSE: {rmse}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-client",
   "metadata": {},
   "source": [
    "With this baseline model, the error is pretty high -- for any given prediction, the model is almost 700 bikes off from the true number of bikes rented, and the model only accounts for about 25% of the variability in the target. From here I will perform feature engineering and iterative model selection to see how much I can improve performance using a basic sklearn regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-nepal",
   "metadata": {},
   "source": [
    "# Split data  \n",
    "Split into train, validation and test splits using default sklearn 80-20 split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acknowledged-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-gather",
   "metadata": {},
   "source": [
    "# Model Selection \n",
    "I will split model selection into 2 sections, one for linear models and one for tree models. I'll test a handful of model and hyperparameter combinations in each category using RandomizedSearchCV, as it provides a decent set of candidates in much less time than grid search. I'll contain all data transformations within a Pipeline object so all transformations on train/val/test sets can be organized and streamlined. I've defined a few helper functions to aid in data transformation inside sklearn ColumnTransformers (see helpers.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-broadway",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "Add all preprocessing steps to a pipeline object. The dataset is clean but I'll include a simple imputer on all steps for consistency and in case a manually supplied feature vector contains missing values. I'll use a custom Dummy Estimator as the last step in the pipeline so I can plug in different models during hyperparameter search. I'll use this same pipeline to test all candidate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "african-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for continuous data\n",
    "con_pipe = Pipeline([('scaler', RobustScaler()),\n",
    "                     ('imputer', SimpleImputer(strategy='median',\n",
    "                                       add_indicator=True))])   \n",
    "\n",
    "# Pipeline for categorical data\n",
    "cat_pipe = Pipeline([('ohe', OneHotEncoder(handle_unknown='ignore')),\n",
    "                     ('imputer', SimpleImputer(strategy='most_frequent',\n",
    "                                       add_indicator=True))])  \n",
    "\n",
    "# Split date column into hour, day of week, day of month, and month columns\n",
    "# Returns 4 new columns @ position 0,1,2,3 in X np array \n",
    "clean_dates = ColumnTransformer([('split_time',  \n",
    "                                  FunctionTransformer(split_dates, \n",
    "                                                      validate=False), \n",
    "                                    ['timestamp'])],\n",
    "                                   sparse_threshold=0,remainder='passthrough') \n",
    "\n",
    "# Combine continuous and categorical steps\n",
    "preprocessing = ColumnTransformer([('categorical', cat_pipe, [0,1,2,3,8,9,10,11]),\n",
    "                                   ('continuous',  con_pipe, [4,5,6,7])],\n",
    "                                   sparse_threshold=0,remainder='passthrough')\n",
    "\n",
    "# Combine all steps and standardize the target to a normal distribution\n",
    "transformer = QuantileTransformer(output_distribution='normal') # transform y\n",
    "pipe = Pipeline([('clean_dates', clean_dates),\n",
    "                 ('preprocessing', preprocessing),\n",
    "                 ('lm',TransformedTargetRegressor(regressor=DummyEstimator(),\n",
    "                                         transformer=transformer))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-ratio",
   "metadata": {},
   "source": [
    "## Linear Models  \n",
    "Define a search space containing all of the linear models I want to try and a range of hyperparameters for each to run through. Pass it all into RandomizedSearchCV with my pipeline as the estimator. Fit the best model on X and y training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "robust-marshall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   34.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
       "       random_state=None, solver='auto', tol=0.001),\n",
       " 0.7105382112528562)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create grid of candidate learning algorithms and their hyperparameters\n",
    "search_space = [{'lm': [LinearRegression()]}, \n",
    "                \n",
    "                {'lm': [Ridge()],  \n",
    "                 'lm__alpha': [1e-6, 1e-3, .1, 1]}, # Regularization strength; constrains coeffs.\n",
    "               \n",
    "                {'lm': [BayesianRidge()], \n",
    "                 'lm__alpha_1': [1e-6, 1e-3, .1, 1], # Scale param for gamma dist prior over alpha.\n",
    "                 'lm__alpha_2': [1e-6, 1e-3, .1, 1]}, # Shape param for gamma dist prior over alpha.\n",
    "                \n",
    "                {'lm': [SGDRegressor()],  \n",
    "                 'lm__loss': ['squared_loss', 'huber', 'epsilon_insensitive', \n",
    "                              'squared_epsilon_insensitive'], # Different variations on MSE to focus more/less on outliers/errors.\n",
    "                 'lm__penalty': ['l2', 'l1', 'elasticnet'], # Type of regularization. Affects how many betas go to 0.\n",
    "                 'lm__alpha': [1e-6, 1e-3, .1, 1]}  # Regularization strength; constrains coeffs.\n",
    "               ]\n",
    "\n",
    "# Good ol' random search\n",
    "lm_algos_rand = RandomizedSearchCV(estimator=pipe, \n",
    "                                    param_distributions=search_space, \n",
    "                                    n_iter=25,\n",
    "                                    cv=5, \n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=1,\n",
    "                                    scoring=['r2','neg_mean_absolute_error', \n",
    "                                             'neg_root_mean_squared_error'],\n",
    "                                    refit='r2',\n",
    "                                    return_train_score=True,\n",
    "                                    random_state=23)\n",
    "\n",
    "#  Fit random search\n",
    "best_linear_model = lm_algos_rand.fit(X_train, y_train)\n",
    "results = lm_algos_rand.cv_results_\n",
    "\n",
    "# View best model\n",
    "best_linear_model.best_estimator_.get_params()['lm'], best_linear_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-oakland",
   "metadata": {},
   "source": [
    "R2 has already significantly improved compared to baseline. I will now try the same feature space but with the new date columns treated as ordinal instead of one-hot-encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-portugal",
   "metadata": {},
   "source": [
    "## Try treating date columns as ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "maritime-nothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   21.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
       "       random_state=None, solver='auto', tol=0.001),\n",
       " 0.7105382112528562)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline for ordinal data (date columns)\n",
    "ord_pipe = Pipeline([('enc', OrdinalEncoder()),\n",
    "                     ('imputer', SimpleImputer(strategy='most_frequent',\n",
    "                                       add_indicator=True))])  \n",
    "\n",
    "# Add to preprocessing \n",
    "preprocessing = ColumnTransformer([('nominal', cat_pipe, [8,9,10,11]),\n",
    "                                   ('continuous',  con_pipe, [4,5,6,7]),\n",
    "                                   ('ordinal', ord_pipe, [0,1,2,3])],\n",
    "                                   sparse_threshold=0,remainder='passthrough')\n",
    "pipe = Pipeline([('clean_dates', clean_dates),\n",
    "                 ('preprocessing', preprocessing),\n",
    "                 ('lm',TransformedTargetRegressor(regressor=DummyEstimator(),\n",
    "                                         transformer=transformer))])\n",
    "\n",
    "# Refit\n",
    "best_linear_model = lm_algos_rand.fit(X_train, y_train)\n",
    "results = lm_algos_rand.cv_results_\n",
    "\n",
    "# View best model\n",
    "best_linear_model.best_estimator_.get_params()['lm'], best_linear_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-commission",
   "metadata": {},
   "source": [
    "R2 is about the same so I will keep this as the best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-uncle",
   "metadata": {},
   "source": [
    "## Validation scores of best linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "average-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.7271373142383262, MAE: 401.89327100856076, RMSE: 576.8705350359055\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_linear_model.predict(X_validation)\n",
    "r2 = r2_score(y_validation, y_pred)\n",
    "mae = mean_absolute_error(y_validation, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_validation, y_pred))\n",
    "print(f\"R2: {r2}, MAE: {mae}, RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-estate",
   "metadata": {},
   "source": [
    "Splitting up the time column significantly improved the model performance right off the bat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-alarm",
   "metadata": {},
   "source": [
    "## Tree Models  \n",
    "Fit tree regression models and compare using same metrics (R2, MAE, RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "humanitarian-raise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                           init=None, learning_rate=0.1, loss='ls', max_depth=10,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=5, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 0.9615908851007546)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same pipeline as before\n",
    "pipe = Pipeline([('clean_dates', clean_dates),\n",
    "                 ('preprocessing', preprocessing),\n",
    "                 ('dt', DummyEstimator())])\n",
    "\n",
    "# Handful of tree regressors and hyperparameter ranges\n",
    "search_space = [{'dt': [DecisionTreeRegressor()],\n",
    "                  'dt__criterion': ['mse', 'friedman_mse', 'mae', 'poisson'], # Method of measuring purity per split.\n",
    "                  'dt__max_depth': [3, 10, 20, None],  # Constrains height of tree. Higher = more complex tree, smaller leaves.\n",
    "                  'dt__min_samples_leaf': [1,2,3,4,5]  # Constrains size of leaf nodes. Higher = less complex tree, large leaves.\n",
    "                  },\n",
    "                \n",
    "                 {'dt': [RandomForestRegressor()],  \n",
    "                  'dt__n_estimators': [100, 200, 300],\n",
    "                  'dt__max_depth': [3, 10, 20, None],     # Constrains height of tree. Higher = more complex tree, smaller leaves.\n",
    "                  'dt__min_samples_leaf': [1,2,3,4,5]},   # Constrains size of leaf nodes. Higher = less complex tree, large leaves.\n",
    "               \n",
    "                 {'dt': [AdaBoostRegressor()],\n",
    "                  'dt__n_estimators': [50, 100, 200]},   # Number of decision trees. Higher = less noise, more computationally expensive.\n",
    "                \n",
    "                 {'dt': [GradientBoostingRegressor()], \n",
    "                  'dt__loss': ['ls', 'lad', 'huber', 'quantile'],  # Loss function to be optimized.\n",
    "                  'dt__max_depth': [3, 10, 20, None],    # Constrains height of tree. Higher = more complex tree, smaller leaves.\n",
    "                  'dt__min_samples_leaf': [1,2,3,4,5]},  # Constrains size of leaf nodes. Higher = less complex tree, large leaves.\n",
    "                \n",
    "                 {'dt': [StackingRegressor(estimators=[('lr', RidgeCV()),('svr', LinearSVR())],\n",
    "                                            final_estimator=RandomForestRegressor(n_estimators=10))]}\n",
    "               ]\n",
    "\n",
    "# Plug everything into random search\n",
    "dt_algos_rand = RandomizedSearchCV(estimator=pipe, \n",
    "                                    param_distributions=search_space, \n",
    "                                    n_iter=25,\n",
    "                                    cv=5, \n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=1,\n",
    "                                    scoring=['r2','neg_mean_absolute_error', 'neg_root_mean_squared_error'],\n",
    "                                    refit='r2',\n",
    "                                    return_train_score=True,\n",
    "                                    random_state=23)\n",
    "\n",
    "# Fit best model on X and y training sets\n",
    "best_tree_model = dt_algos_rand.fit(X_train, y_train);\n",
    "\n",
    "# View best model\n",
    "best_tree_model.best_estimator_.get_params()['dt'], best_tree_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-hours",
   "metadata": {},
   "source": [
    "## Validation scores of best tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "armed-coffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9638082899763685, MAE: 111.23474727827363, RMSE: 210.09263786419288\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_tree_model.predict(X_validation)\n",
    "r2 = r2_score(y_validation, y_pred)\n",
    "mae = mean_absolute_error(y_validation, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_validation, y_pred))\n",
    "print(f\"R2: {r2}, MAE: {mae}, RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-browser",
   "metadata": {},
   "source": [
    "This model yields the lowest errors and highest R2 yet. The model now accounts for about 95% of the variability in y and is only about 118 bikes off in prediction compared to almost 700 with the baseline OLS linear regression. I will choose this as my final model and use it to calculate test error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-literacy",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('clean_dates', clean_dates),\n",
    "                 ('preprocessing', preprocessing),\n",
    "                 ('dt',GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
    "                           init=None, learning_rate=0.1, loss='ls', max_depth=10,\n",
    "                           max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=5, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_iter_no_change=None, presort='deprecated',\n",
    "                           random_state=None, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0, warm_start=False))])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-memory",
   "metadata": {},
   "source": [
    "# Visual representation of pipeline and best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "laden-procedure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clean_dates',\n",
       "  ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0,\n",
       "                    transformer_weights=None,\n",
       "                    transformers=[('split_time',\n",
       "                                   FunctionTransformer(accept_sparse=False,\n",
       "                                                       check_inverse=True,\n",
       "                                                       func=<function split_dates at 0x7fe7e91f5160>,\n",
       "                                                       inv_kw_args=None,\n",
       "                                                       inverse_func=None,\n",
       "                                                       kw_args=None,\n",
       "                                                       validate=False),\n",
       "                                   ['timestamp'])],\n",
       "                    verbose=False)),\n",
       " ('preprocessing',\n",
       "  ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0,\n",
       "                    transformer_weights=None,\n",
       "                    transformers=[('nominal',\n",
       "                                   Pipeline(memory=None,\n",
       "                                            steps=[('ohe',\n",
       "                                                    OneHotEncoder(categories='auto',\n",
       "                                                                  drop=None,\n",
       "                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                  handle_unknown='ignore',\n",
       "                                                                  sparse=True)),\n",
       "                                                   ('imputer',\n",
       "                                                    SimpleImputer(add_indicator=True,\n",
       "                                                                  copy=True,\n",
       "                                                                  fill_value=None,\n",
       "                                                                  missing_value...\n",
       "                                                                  missing_values=nan,\n",
       "                                                                  strategy='median',\n",
       "                                                                  verbose=0))],\n",
       "                                            verbose=False),\n",
       "                                   [4, 5, 6, 7]),\n",
       "                                  ('ordinal',\n",
       "                                   Pipeline(memory=None,\n",
       "                                            steps=[('enc',\n",
       "                                                    OrdinalEncoder(categories='auto',\n",
       "                                                                   dtype=<class 'numpy.float64'>)),\n",
       "                                                   ('imputer',\n",
       "                                                    SimpleImputer(add_indicator=True,\n",
       "                                                                  copy=True,\n",
       "                                                                  fill_value=None,\n",
       "                                                                  missing_values=nan,\n",
       "                                                                  strategy='most_frequent',\n",
       "                                                                  verbose=0))],\n",
       "                                            verbose=False),\n",
       "                                   [0, 1, 2, 3])],\n",
       "                    verbose=False)),\n",
       " ('dt',\n",
       "  GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                            init=None, learning_rate=0.1, loss='ls', max_depth=10,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                            min_samples_leaf=5, min_samples_split=2,\n",
       "                            min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                            n_iter_no_change=None, presort='deprecated',\n",
       "                            random_state=None, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-browse",
   "metadata": {},
   "source": [
    "## Test scores of final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "compliant-rider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.964843647675953, MAE: 109.86228957299994, RMSE: 201.50038097098943\n"
     ]
    }
   ],
   "source": [
    "pipe.predict(X_test)\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"R2: {r2}, MAE: {mae}, RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-petroleum",
   "metadata": {},
   "source": [
    "This is the highest R2 and lowest error yet. Now the model is only around 109 bikes off on any given prediction compared to 900 off on the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-conclusion",
   "metadata": {},
   "source": [
    "## Feature Importance  \n",
    "Look at the relative feature importance of the different predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "burning-qualification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.7284\n",
       "                \n",
       "                    &plusmn; 0.4455\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                season_0.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.64%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0570\n",
       "                \n",
       "                    &plusmn; 0.0610\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                is_holiday_0.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.56%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0361\n",
       "                \n",
       "                    &plusmn; 0.0935\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                season_2.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0329\n",
       "                \n",
       "                    &plusmn; 0.0811\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                is_holiday_1.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0315\n",
       "                \n",
       "                    &plusmn; 0.1314\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                is_weekend_0.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0266\n",
       "                \n",
       "                    &plusmn; 0.0270\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weather_code_2.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0166\n",
       "                \n",
       "                    &plusmn; 0.0335\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weather_code_3.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0127\n",
       "                \n",
       "                    &plusmn; 0.0184\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                t1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0116\n",
       "                \n",
       "                    &plusmn; 0.1433\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                season_1.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0115\n",
       "                \n",
       "                    &plusmn; 0.0169\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weather_code_1.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.08%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0090\n",
       "                \n",
       "                    &plusmn; 0.0165\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                wind_speed\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.15%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0080\n",
       "                \n",
       "                    &plusmn; 0.0760\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                season_3.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0075\n",
       "                \n",
       "                    &plusmn; 0.1449\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                is_weekend_1.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0127\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weather_code_26.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0015\n",
       "                \n",
       "                    &plusmn; 0.0312\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                hour\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0187\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weather_code_10.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0214\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                dayofweek\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0211\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weather_code_7.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0312\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                dayofmonth\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0002\n",
       "                \n",
       "                    &plusmn; 0.0133\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                month\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0002\n",
       "                \n",
       "                    &plusmn; 0.0188\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                weather_code_4.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0076\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                t2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.99%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0028\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                hum\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\\n                          init=None, learning_rate=0.1, loss='ls', max_depth=10,\\n                          max_features=None, max_leaf_nodes=None,\\n                          min_impurity_decrease=0.0, min_impurity_split=None,\\n                          min_samples_leaf=5, min_samples_split=2,\\n                          min_weight_fraction_leaf=0.0, n_estimators=100,\\n                          n_iter_no_change=None, presort='deprecated',\\n                          random_state=None, subsample=1.0, tol=0.0001,\\n                          validation_fraction=0.1, verbose=0, warm_start=False)\", description='\\nRandom forest feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=True, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='season_0.0', weight=0.7284234671958035, std=0.22277094264921496, value=None), FeatureWeight(feature='is_holiday_0.0', weight=0.056967424259961666, std=0.030514436035239113, value=None), FeatureWeight(feature='season_2.0', weight=0.03613110038164908, std=0.0467424582931073, value=None), FeatureWeight(feature='is_holiday_1.0', weight=0.0328758885811731, std=0.0405686286876645, value=None), FeatureWeight(feature='is_weekend_0.0', weight=0.03147795082246775, std=0.06568720501780252, value=None), FeatureWeight(feature='weather_code_2.0', weight=0.026604999756103382, std=0.013509976538259647, value=None), FeatureWeight(feature='weather_code_3.0', weight=0.016637003674002185, std=0.016729486874132487, value=None), FeatureWeight(feature='t1', weight=0.012670489962021027, std=0.009193056437603386, value=None), FeatureWeight(feature='season_1.0', weight=0.011552093825479372, std=0.07165108297843377, value=None), FeatureWeight(feature='weather_code_1.0', weight=0.011498526786862414, std=0.008439598803184848, value=None), FeatureWeight(feature='wind_speed', weight=0.008992584943161182, std=0.008244989911393868, value=None), FeatureWeight(feature='season_3.0', weight=0.007958212856499988, std=0.038013244616131196, value=None), FeatureWeight(feature='is_weekend_1.0', weight=0.00746896408725288, std=0.07242560772967915, value=None), FeatureWeight(feature='weather_code_26.0', weight=0.006734853358092238, std=0.006325521481066017, value=None), FeatureWeight(feature='hour', weight=0.0015302061186631018, std=0.015584521239302627, value=None), FeatureWeight(feature='weather_code_10.0', weight=0.0007569290354381645, std=0.009338417892186297, value=None), FeatureWeight(feature='dayofweek', weight=0.00043107610979230065, std=0.010697289403019858, value=None), FeatureWeight(feature='weather_code_7.0', weight=0.00041892603179816037, std=0.010531529581852233, value=None), FeatureWeight(feature='dayofmonth', weight=0.00039848577544063766, std=0.015617793473137813, value=None), FeatureWeight(feature='month', weight=0.0001894187128616318, std=0.006655465347417076, value=None), FeatureWeight(feature='weather_code_4.0', weight=0.000169904953172969, std=0.009390520460329213, value=None), FeatureWeight(feature='t2', weight=0.00010593096686598075, std=0.0038090573564775036, value=None), FeatureWeight(feature='hum', weight=5.561805437203455e-06, std=0.00138611241785002, value=None)], remaining=0), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get names of one-hot-encoded categorical columns\n",
    "onehot_cat_columns = list(pipe.named_steps['preprocessing']\\\n",
    "                          .named_transformers_['nominal']\\\n",
    "                          .named_steps['ohe']\\\n",
    "                          .get_feature_names(input_features=['weather_code','is_holiday','is_weekend', 'season']))\n",
    "\n",
    "# Get names of one-hot-encoded ordinal columns\n",
    "onehot_ord_columns = ['hour', 'dayofmonth', 'dayofweek', 'month']\n",
    "\n",
    "# Names of numeric features \n",
    "numeric_features_list = ['t1', 't2', 'hum', 'wind_speed']\n",
    "\n",
    "# Combine all feature names in the order the appear in the np array made by the pipeline\n",
    "onehot_ord_columns.extend(numeric_features_list)\n",
    "onehot_ord_columns.extend(onehot_cat_columns)\n",
    "\n",
    "# Visualize feature importance\n",
    "eli5.explain_weights(pipe.named_steps['dt'], top=50, feature_names=onehot_ord_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-disabled",
   "metadata": {},
   "source": [
    "# Final Model Interpretation\n",
    "The final model that was chosen was a Gradient Boosting Regressor. Preprocessing and adding extra date columns significantly improved model performance from baseline. Overall the R2 of the model was around 0.96, indicating that around 96% of the variability in the target is explained by the regression tree. While running randomizedCV on the different tree algorithms helped to isolate the best algorithm to use, there didn't seem to be much variablity in performance within the Gradient Boosting Regressor in terms of hyperparameters. Overall the performance of the model was stable. \n",
    "\n",
    "The most important feature, with a significantly higher weight than all the other features, was dummy variable Season_0.0, aka Spring. This makes sense as Spring has long periods of daylight and mild temperatures in London where this data was collected. The next most important features were holiday and weekend, indicating that these bikes may be used for daily commutes to work. The second most influential season was Summer, which also makes sense for recreational outdoor bike riding.  \n",
    "  \n",
    "This model could be very helpful to bike rental companies as it provides a prediction of the number of bikes that will be rented on a given day at a given time. Rental companies could leverage these predictions to improve advertising efficiency or strategically increase/decrease numbers of available bikes based on circumstance.  \n",
    "  \n",
    "Future steps could include expanding the scope of the model to bike rentals outside London or incorporating exogenous variables such as information about individual customers and their rental habits. Additionally, one could build a time series model to map changes in cumulative bike rentals over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-shoulder",
   "metadata": {},
   "source": [
    "# Save model to pass into app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eight-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(pipe, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
